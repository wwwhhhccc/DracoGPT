{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67a222f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "cwd = os.getcwd()\n",
    "\n",
    "# Assuming the target directory is one level up from the current working directory\n",
    "parent_dir = os.path.dirname(cwd)\n",
    "\n",
    "# Add the parent directory to sys.path\n",
    "sys.path.append(parent_dir)\n",
    "\n",
    "from draco import Draco\n",
    "import json\n",
    "import shutil\n",
    "import pandas as pd\n",
    "from typing import Dict, List, Any\n",
    "import pickle\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from sklearn import svm\n",
    "\n",
    "import plotly.figure_factory as ff\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "\n",
    "from draco.data_utils import pairs_to_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e43cb79",
   "metadata": {},
   "outputs": [],
   "source": [
    "default_draco = Draco()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4771de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def train_model(data: pd.DataFrame, test_size: float = 0.3, C_values: list = [0.1, 0.5, 1, 5, 10], quiet=False):\n",
    "    # Prepare the data\n",
    "    X = data.negative - data.positive\n",
    "    size = len(X)\n",
    "    y = np.ones(size)\n",
    "\n",
    "    # Flip a few examples at random\n",
    "    idx = np.random.choice([False, True], size=size, p=[0.5, 0.5])\n",
    "    X[idx] = -X[idx]\n",
    "    y[idx] = -y[idx]\n",
    "\n",
    "    # Split the data into train and dev sets\n",
    "    X_train, X_dev, y_train, y_dev = train_test_split(X, y, test_size=test_size)\n",
    "\n",
    "    best_score = 0\n",
    "    best_C = C_values[0]\n",
    "\n",
    "    # Grid search on C\n",
    "    for C in C_values:\n",
    "        clf = svm.LinearSVC(C=C, fit_intercept=False)\n",
    "        clf.fit(X_train, y_train)\n",
    "        score = clf.score(X_dev, y_dev)\n",
    "\n",
    "        if not quiet:\n",
    "            print(f\"C: {C}, Dev score: {score}\")\n",
    "\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_C = C\n",
    "\n",
    "    # Retrain on the entire dataset with the best C\n",
    "    clf_final = svm.LinearSVC(C=best_C, fit_intercept=False)\n",
    "    clf_final.fit(X, y)\n",
    "\n",
    "    if not quiet:\n",
    "        print(\"Best C: \", best_C)\n",
    "        print(\"Final Train Score: \", clf_final.score(X, y))\n",
    "\n",
    "    return clf_final\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "093eece2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def swap_json_fields(json_file_path, ranks):\n",
    "    # Read the JSON file\n",
    "   \n",
    "    with open(json_file_path, 'r') as file:\n",
    "        json_data = json.load(file)\n",
    "\n",
    "    if len(json_data) != len(ranks):\n",
    "        raise ValueError(\"Length of ranks does not match the number of JSON objects in the file\")\n",
    "    \n",
    "    print(\"swapping and writing:\",len(json_data), len(ranks))\n",
    "    \n",
    "    updated_json_data = []\n",
    "    i = 1\n",
    "    for json_obj, chart in zip(json_data, ranks):\n",
    "        if chart == \"chart 2\":\n",
    "            # Swap 'positive' and 'negative' fields\n",
    "            # copy file f'./DracoGPT_data/kim2018/{i}_neg_first.txt' to f'./DracoGPT_data/kim2018_for_reader/agree/{i}.txt'\n",
    "            source_file = f'./DracoGPT_data/kim2018/{i}_neg_first.txt'\n",
    "            destination_file = f'./DracoGPT_data/kim2018_for_reader/disagree/{i}.txt'\n",
    "            shutil.copyfile(source_file, destination_file)\n",
    "            \n",
    "            json_obj['positive'], json_obj['negative'] = json_obj['negative'], json_obj['positive']\n",
    "            updated_json_data.append(json_obj)\n",
    "        elif chart == \"chart 1\":\n",
    "            # Keep the json_obj as is\n",
    "            source_file = f'./DracoGPT_data/kim2018/{i}_pos_first.txt'\n",
    "            destination_file = f'./DracoGPT_data/kim2018_for_reader/agree/{i}.txt'\n",
    "            shutil.copyfile(source_file, destination_file)\n",
    "            \n",
    "            \n",
    "            updated_json_data.append(json_obj)\n",
    "        elif chart == \"conflicting\":\n",
    "            source_file = f'./DracoGPT_data/kim2018/{i}_pos_first.txt'\n",
    "            destination_file = f'./DracoGPT_data/kim2018_for_reader/conflict/{i}.txt'\n",
    "            shutil.copyfile(source_file, destination_file)\n",
    "            \n",
    "            f'./DracoGPT_data/kim2018/{i}_pos_first.txt'\n",
    "            i += 1\n",
    "            continue\n",
    "        else:\n",
    "            # Raise an error for any other value\n",
    "            raise ValueError(f\"Invalid value in ranks: {chart}\")\n",
    "        i += 1\n",
    "    print(\"final i\", i)\n",
    "    return updated_json_data\n",
    "\n",
    "\n",
    "# json_file_path = f'./DracoGPT_data/kim2018_GPT/kim2018_draco2.json'\n",
    "# len(swap_json_fields(json_file_path, res_kim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f11af54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['chart 2', 'chart 2', 'chart 2', 'chart 2', 'chart 2', 'chart 2', 'chart 2', 'conflicting', 'chart 1', 'chart 2', 'conflicting', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'conflicting', 'conflicting', 'conflicting', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'chart 2', 'conflicting', 'chart 2', 'chart 2', 'conflicting', 'conflicting', 'chart 1', 'chart 2', 'conflicting', 'conflicting', 'chart 1', 'conflicting', 'chart 1', 'conflicting', 'chart 1', 'conflicting', 'conflicting', 'chart 1', 'conflicting', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'chart 2', 'conflicting', 'conflicting', 'conflicting', 'chart 1', 'chart 1', 'conflicting', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'conflicting', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'conflicting', 'chart 2', 'chart 2', 'chart 2', 'chart 2', 'chart 2', 'chart 2', 'chart 2', 'conflicting', 'conflicting', 'conflicting', 'chart 2', 'conflicting', 'chart 2', 'chart 2', 'chart 2', 'chart 2', 'chart 2', 'chart 2', 'chart 2', 'chart 2', 'chart 2', 'chart 1', 'conflicting', 'conflicting', 'conflicting', 'conflicting', 'conflicting', 'chart 2', 'conflicting', 'chart 1', 'conflicting', 'chart 1', 'chart 1', 'chart 2', 'chart 2', 'conflicting', 'chart 2', 'chart 2', 'chart 2', 'chart 2', 'chart 2', 'chart 2', 'chart 2', 'conflicting', 'conflicting', 'chart 2', 'chart 2', 'conflicting', 'conflicting', 'chart 2', 'conflicting', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'chart 2', 'conflicting', 'conflicting', 'conflicting', 'chart 1', 'chart 1', 'conflicting', 'chart 1', 'conflicting', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'conflicting', 'conflicting', 'chart 2', 'chart 2', 'chart 2', 'chart 2', 'conflicting', 'conflicting', 'chart 1', 'conflicting', 'chart 2', 'chart 1', 'chart 1', 'chart 2', 'conflicting', 'chart 2', 'chart 2', 'conflicting', 'chart 1', 'conflicting', 'conflicting', 'chart 1', 'chart 1', 'conflicting', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'conflicting', 'conflicting', 'conflicting', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'chart 2', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'conflicting', 'conflicting', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'chart 2', 'conflicting', 'conflicting', 'conflicting', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'conflicting', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'conflicting', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'conflicting', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'chart 2', 'conflicting', 'conflicting', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'chart 2', 'conflicting', 'conflicting', 'conflicting', 'conflicting', 'chart 1', 'conflicting', 'chart 1', 'conflicting', 'chart 2', 'chart 2', 'chart 2', 'conflicting', 'chart 2', 'chart 2', 'chart 2', 'conflicting', 'conflicting', 'conflicting', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'chart 2', 'conflicting', 'conflicting', 'conflicting', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'conflicting', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'chart 2', 'chart 1', 'chart 2', 'conflicting', 'conflicting', 'conflicting', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'chart 2', 'conflicting', 'conflicting', 'conflicting', 'chart 1', 'chart 1', 'conflicting', 'chart 1', 'conflicting', 'chart 1', 'conflicting', 'chart 2', 'chart 2', 'chart 2', 'chart 2', 'conflicting', 'chart 2', 'chart 2', 'chart 1', 'chart 2', 'conflicting', 'chart 2', 'chart 1', 'conflicting', 'chart 2', 'chart 1', 'chart 1', 'conflicting', 'chart 1', 'conflicting', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'chart 2', 'conflicting', 'conflicting', 'chart 1', 'chart 1', 'conflicting', 'conflicting', 'chart 1', 'chart 1', 'chart 2', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'conflicting', 'conflicting', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'chart 2', 'chart 1', 'chart 2', 'chart 1', 'chart 1', 'chart 2', 'chart 2', 'conflicting', 'conflicting', 'conflicting', 'conflicting', 'chart 2', 'chart 2', 'chart 2', 'chart 2', 'chart 2', 'conflicting', 'chart 2', 'chart 1', 'chart 1', 'chart 1', 'chart 2', 'chart 2', 'conflicting', 'chart 2', 'chart 1', 'conflicting', 'chart 1', 'conflicting', 'conflicting', 'chart 1', 'conflicting', 'chart 2', 'chart 1', 'conflicting', 'conflicting', 'chart 1', 'chart 1', 'conflicting', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'conflicting', 'chart 2', 'conflicting', 'conflicting', 'conflicting', 'chart 2', 'chart 1', 'conflicting', 'chart 1', 'chart 2', 'chart 2', 'chart 2', 'conflicting', 'chart 2', 'chart 1', 'chart 1', 'conflicting', 'conflicting', 'chart 1', 'chart 1', 'conflicting', 'chart 1', 'chart 1', 'chart 2', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'chart 2', 'conflicting', 'conflicting', 'chart 1', 'chart 1', 'conflicting', 'chart 1', 'chart 1', 'chart 1', 'chart 2', 'conflicting', 'chart 2', 'chart 2', 'chart 2', 'chart 2', 'conflicting', 'conflicting', 'conflicting', 'conflicting', 'chart 2', 'chart 2', 'chart 2', 'chart 2', 'chart 2', 'chart 2', 'chart 2', 'chart 2', 'chart 2', 'conflicting', 'chart 2', 'conflicting', 'conflicting', 'chart 2', 'chart 1', 'chart 2', 'chart 1', 'chart 1', 'conflicting', 'conflicting', 'conflicting', 'chart 1', 'conflicting', 'conflicting', 'conflicting', 'conflicting', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'chart 2', 'chart 1', 'chart 1', 'chart 1', 'chart 2', 'chart 2', 'chart 2', 'conflicting', 'chart 2', 'chart 2', 'chart 2', 'chart 2', 'chart 2', 'chart 2', 'conflicting', 'conflicting', 'chart 2', 'chart 1', 'chart 2', 'chart 1', 'conflicting', 'conflicting', 'conflicting', 'chart 1', 'conflicting', 'chart 2', 'conflicting', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'chart 2', 'conflicting', 'conflicting', 'chart 1', 'chart 1', 'conflicting', 'conflicting', 'chart 1', 'chart 1', 'chart 2', 'chart 1', 'chart 1', 'conflicting', 'conflicting', 'chart 1', 'conflicting', 'chart 2', 'conflicting', 'chart 2', 'chart 1', 'conflicting', 'conflicting', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'conflicting', 'conflicting', 'chart 1', 'conflicting', 'chart 2', 'conflicting', 'chart 2', 'chart 2', 'chart 1', 'conflicting', 'chart 1', 'chart 1', 'conflicting', 'chart 1', 'conflicting', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'conflicting', 'conflicting', 'conflicting', 'chart 1', 'chart 1', 'conflicting', 'conflicting', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'conflicting', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'chart 2', 'chart 1', 'chart 2', 'conflicting', 'chart 2', 'chart 2', 'chart 1', 'chart 1', 'conflicting', 'chart 1', 'conflicting', 'chart 2', 'chart 1', 'chart 1', 'chart 2', 'chart 1', 'chart 2', 'conflicting', 'chart 2', 'chart 1', 'chart 1', 'conflicting', 'conflicting', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'conflicting', 'conflicting', 'chart 1', 'conflicting', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'conflicting', 'chart 2', 'chart 1', 'chart 1', 'conflicting', 'conflicting', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'conflicting', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'conflicting', 'chart 1', 'chart 1', 'chart 2', 'conflicting', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'chart 2', 'chart 2', 'conflicting', 'chart 2', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'chart 2', 'chart 2', 'chart 2', 'chart 2', 'chart 2', 'chart 2', 'conflicting', 'conflicting', 'chart 2', 'chart 2', 'conflicting', 'chart 2', 'conflicting', 'conflicting', 'chart 2', 'chart 2', 'conflicting', 'conflicting', 'chart 1', 'conflicting', 'chart 2', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'chart 2', 'conflicting', 'conflicting', 'conflicting', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'chart 2', 'conflicting', 'chart 1', 'chart 2', 'conflicting', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'chart 2', 'conflicting', 'conflicting', 'chart 2', 'conflicting', 'chart 1', 'conflicting', 'chart 1', 'conflicting', 'chart 1', 'chart 2', 'chart 2', 'chart 2', 'chart 2', 'chart 2', 'chart 2', 'chart 1', 'chart 2', 'chart 2', 'chart 2', 'conflicting', 'chart 2', 'chart 2', 'conflicting', 'conflicting', 'chart 2', 'conflicting', 'conflicting', 'chart 1', 'chart 2', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'conflicting', 'conflicting', 'chart 1', 'chart 1', 'chart 1', 'conflicting', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'conflicting', 'conflicting', 'chart 1', 'chart 1', 'chart 1', 'conflicting', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'conflicting', 'chart 2', 'conflicting', 'chart 1', 'chart 1', 'chart 1', 'conflicting', 'chart 1', 'conflicting', 'chart 1', 'conflicting', 'conflicting', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'conflicting', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'conflicting', 'chart 2', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'conflicting', 'conflicting', 'chart 1', 'chart 1', 'conflicting', 'conflicting', 'conflicting', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'conflicting', 'conflicting', 'chart 1', 'chart 1', 'chart 1', 'conflicting', 'chart 1', 'chart 1', 'chart 1', 'chart 2', 'chart 2', 'chart 2', 'chart 2', 'chart 2', 'chart 2', 'conflicting', 'chart 1', 'chart 1', 'chart 1', 'conflicting', 'chart 1', 'conflicting', 'chart 1', 'chart 1', 'chart 1', 'conflicting', 'conflicting', 'chart 2', 'chart 2', 'chart 2', 'chart 1', 'chart 2', 'chart 2', 'chart 2', 'conflicting', 'conflicting', 'chart 2', 'conflicting', 'conflicting', 'chart 2', 'chart 1', 'chart 2', 'chart 1', 'chart 2', 'chart 2', 'chart 1', 'conflicting', 'conflicting', 'conflicting', 'conflicting', 'conflicting', 'conflicting', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'conflicting', 'conflicting', 'conflicting', 'chart 1', 'chart 1', 'conflicting', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'conflicting', 'chart 1', 'chart 1', 'chart 2', 'conflicting', 'conflicting', 'conflicting', 'conflicting', 'chart 1', 'conflicting', 'chart 1', 'chart 1', 'conflicting', 'chart 1', 'chart 2', 'chart 1', 'conflicting', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'conflicting', 'conflicting', 'conflicting', 'conflicting', 'chart 1', 'chart 1', 'conflicting', 'conflicting', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'conflicting', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'chart 2', 'chart 2', 'chart 2', 'conflicting', 'chart 2', 'chart 1', 'conflicting', 'conflicting', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'conflicting', 'conflicting', 'chart 2', 'conflicting', 'conflicting', 'chart 1', 'conflicting', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'conflicting', 'conflicting', 'chart 1', 'chart 1', 'conflicting', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'conflicting', 'conflicting', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'chart 2', 'conflicting', 'conflicting', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'chart 2', 'chart 2', 'conflicting', 'conflicting', 'chart 1', 'chart 1', 'conflicting', 'chart 1', 'conflicting', 'chart 1', 'chart 2', 'chart 2', 'chart 2', 'chart 2', 'chart 1', 'chart 2', 'chart 1', 'chart 2', 'conflicting', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'chart 2', 'conflicting', 'conflicting', 'chart 1', 'chart 1', 'conflicting', 'conflicting', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'chart 2', 'chart 1', 'conflicting', 'chart 2', 'conflicting', 'conflicting', 'chart 2', 'chart 2', 'chart 2', 'chart 2', 'chart 2', 'chart 2', 'conflicting', 'chart 2', 'chart 2', 'chart 2', 'conflicting', 'conflicting', 'conflicting', 'conflicting', 'chart 2', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'conflicting', 'conflicting', 'chart 1', 'chart 1', 'conflicting', 'conflicting', 'conflicting', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'chart 1', 'conflicting', 'conflicting', 'chart 1', 'chart 1', 'chart 1', 'conflicting', 'chart 1', 'chart 1', 'conflicting']\n",
      "Percentage of 'chart 1': 53.645833333333336%\n",
      "Percentage of 'chart 2': 19.70486111111111%\n",
      "Percentage of 'conflicting': 26.649305555555557%\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "res_kim = None\n",
    "def load_data(model, temp):\n",
    "    kim_file_path = f'./gpt_responses/kim2018_{model}_{temp}_ranking.pkl'\n",
    "\n",
    "    # Load the data from kim_GPT.pkl\n",
    "    with open(kim_file_path, 'rb') as file:\n",
    "        res_kim = pickle.load(file)\n",
    "\n",
    "\n",
    "    # Combine the lists\n",
    "    combined_list = res_kim\n",
    "    return combined_list, res_kim\n",
    "\n",
    "combined_list, res_kim = load_data('gpt-4-1106-preview', 0)\n",
    "print(combined_list)\n",
    "\n",
    "# Count occurrences\n",
    "count_chart_1 = combined_list.count('chart 1')\n",
    "count_chart_2 = combined_list.count('chart 2')\n",
    "count_conflicting = combined_list.count('conflicting')\n",
    "\n",
    "# Calculate total number of items for percentage calculation\n",
    "total_items = len(combined_list)\n",
    "\n",
    "# Calculate percentages\n",
    "percentage_chart_1 = (count_chart_1 / total_items) * 100\n",
    "percentage_chart_2 = (count_chart_2 / total_items) * 100\n",
    "percentage_conflicting = (count_conflicting / total_items) * 100\n",
    "\n",
    "# Print results\n",
    "print(f\"Percentage of 'chart 1': {percentage_chart_1}%\")\n",
    "print(f\"Percentage of 'chart 2': {percentage_chart_2}%\")\n",
    "print(f\"Percentage of 'conflicting': {percentage_conflicting}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1e822734",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "swapping and writing: 1152 1152\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './DracoGPT_data/kim2018/1_neg_first.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 16\u001b[0m\n\u001b[1;32m      7\u001b[0m         json\u001b[38;5;241m.\u001b[39mdump(updated_json, file, indent \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m4\u001b[39m)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m#     json_file_path = f'./DracoGPT_data/saket2018_GPT/saket2018_draco2.json'\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m#     updated_json = swap_json_fields(json_file_path, res_saket)\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m#     directory = os.path.dirname(json_file_path)\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m#     new_file_path = os.path.join(directory, f'modified_saket_{model}_{temp}.json')\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m#     with open(new_file_path, 'w') as file:\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m#         json.dump(updated_json, file, indent = 4)\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m write_GPT_training_data(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgpt-4-1106-preview\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m0\u001b[39m)\n",
      "Cell \u001b[0;32mIn[7], line 3\u001b[0m, in \u001b[0;36mwrite_GPT_training_data\u001b[0;34m(model, temp)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrite_GPT_training_data\u001b[39m(model, temp):\n\u001b[1;32m      2\u001b[0m     json_file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./data/kim2018_draco2.json\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 3\u001b[0m     updated_json \u001b[38;5;241m=\u001b[39m swap_json_fields(json_file_path, res_kim)\n\u001b[1;32m      4\u001b[0m     directory \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mdirname(json_file_path)\n\u001b[1;32m      5\u001b[0m     new_file_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(directory, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodified_kim_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtemp\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.json\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[5], line 20\u001b[0m, in \u001b[0;36mswap_json_fields\u001b[0;34m(json_file_path, ranks)\u001b[0m\n\u001b[1;32m     18\u001b[0m source_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./DracoGPT_data/kim2018/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_neg_first.txt\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     19\u001b[0m destination_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./DracoGPT_data/kim2018_for_reader/disagree/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.txt\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m---> 20\u001b[0m shutil\u001b[38;5;241m.\u001b[39mcopyfile(source_file, destination_file)\n\u001b[1;32m     22\u001b[0m json_obj[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpositive\u001b[39m\u001b[38;5;124m'\u001b[39m], json_obj[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnegative\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m json_obj[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnegative\u001b[39m\u001b[38;5;124m'\u001b[39m], json_obj[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpositive\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     23\u001b[0m updated_json_data\u001b[38;5;241m.\u001b[39mappend(json_obj)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/shutil.py:256\u001b[0m, in \u001b[0;36mcopyfile\u001b[0;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[1;32m    254\u001b[0m     os\u001b[38;5;241m.\u001b[39msymlink(os\u001b[38;5;241m.\u001b[39mreadlink(src), dst)\n\u001b[1;32m    255\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 256\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(src, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m fsrc:\n\u001b[1;32m    257\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    258\u001b[0m             \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(dst, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m fdst:\n\u001b[1;32m    259\u001b[0m                 \u001b[38;5;66;03m# macOS\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './DracoGPT_data/kim2018/1_neg_first.txt'"
     ]
    }
   ],
   "source": [
    "\n",
    "def write_GPT_training_data(model, temp):\n",
    "    json_file_path = './data/kim2018_draco2.json'\n",
    "    updated_json = swap_json_fields(json_file_path, res_kim)\n",
    "    directory = os.path.dirname(json_file_path)\n",
    "    new_file_path = os.path.join(directory, f'modified_kim_{model}_{temp}.json')\n",
    "    with open(new_file_path, 'w') as file:\n",
    "        json.dump(updated_json, file, indent = 4)\n",
    "    \n",
    "#     json_file_path = f'./DracoGPT_data/saket2018_GPT/saket2018_draco2.json'\n",
    "#     updated_json = swap_json_fields(json_file_path, res_saket)\n",
    "#     directory = os.path.dirname(json_file_path)\n",
    "#     new_file_path = os.path.join(directory, f'modified_saket_{model}_{temp}.json')\n",
    "#     with open(new_file_path, 'w') as file:\n",
    "#         json.dump(updated_json, file, indent = 4)\n",
    "\n",
    "write_GPT_training_data('gpt-4-1106-preview', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "562e1e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_combined_list = [element for element in combined_list if element in ['chart 1', 'chart 2']]\n",
    "\n",
    "\n",
    "index_map = {}\n",
    "filtered_index = 0\n",
    "\n",
    "for original_index, value in enumerate(combined_list):\n",
    "    if value in [\"chart 1\", \"chart 2\"]:\n",
    "        index_map[filtered_index] = original_index\n",
    "        filtered_index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e46a092c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:draco.data_utils:Running 85 partitions of 845 items in parallel on {processes} processes.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training DracoGPT on Kim data\n",
      "845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:draco.data_utils:Hash of dataframe: -5562377976351535379\n",
      "/Users/huichenwang/anaconda3/lib/python3.11/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/Users/huichenwang/anaconda3/lib/python3.11/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/Users/huichenwang/anaconda3/lib/python3.11/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/Users/huichenwang/anaconda3/lib/python3.11/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/Users/huichenwang/anaconda3/lib/python3.11/site-packages/sklearn/svm/_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "C: 0.1, Dev score: 0.9881889763779528\n",
      "C: 0.5, Dev score: 0.984251968503937\n",
      "C: 1, Dev score: 0.984251968503937\n",
      "C: 5, Dev score: 0.984251968503937\n",
      "C: 10, Dev score: 0.984251968503937\n",
      "Best C:  0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/huichenwang/anaconda3/lib/python3.11/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/Users/huichenwang/anaconda3/lib/python3.11/site-packages/sklearn/svm/_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/huichenwang/anaconda3/lib/python3.11/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "INFO:draco.data_utils:Running 31 partitions of 307 items in parallel on {processes} processes.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Train Score:  0.98698224852071\n",
      "Index(['aggregate', 'aggregate_count', 'aggregate_group_by_raw',\n",
      "       'aggregate_max', 'aggregate_mean', 'aggregate_median', 'aggregate_min',\n",
      "       'aggregate_no_discrete', 'aggregate_stdev', 'aggregate_sum',\n",
      "       ...\n",
      "       'value_line', 'value_point', 'value_rect', 'value_text', 'value_tick',\n",
      "       'x_col', 'x_row', 'x_y_raw', 'y_col', 'y_row'],\n",
      "      dtype='object', length=147)\n",
      "1152 1152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:draco.data_utils:Hash of dataframe: -753024968425796386\n"
     ]
    }
   ],
   "source": [
    "def train_data_prep(model, temp):\n",
    "    kim = {}\n",
    "#     saket = {}\n",
    "#     with open(f'./DracoGPT_Data/saket2018_GPT/modified_saket_{model}_{temp}.json') as file:\n",
    "\n",
    "#         i = 0\n",
    "#         json_data = json.load(file)\n",
    "\n",
    "#         for pair in json_data:\n",
    "#             pair[\"source\"] = \"saket\"\n",
    "#             pair[\"pair_id\"] = f'{pair[\"source\"]}_{i}'\n",
    "#             saket[pair[\"pair_id\"]] = pair\n",
    "#             i += 1\n",
    "\n",
    "\n",
    "    with open(f'./DracoGPT_Data/kim2018_GPT/modified_kim_{model}_{temp}.json') as file:\n",
    "\n",
    "        i = 0\n",
    "        json_data = json.load(file)\n",
    "        print(len(json_data))\n",
    "        for pair in json_data:\n",
    "            pair[\"source\"] = \"kim\"\n",
    "            pair[\"pair_id\"] = f'{pair[\"source\"]}_{index_map[i]}'\n",
    "            kim[pair[\"pair_id\"]] = pair\n",
    "            i += 1\n",
    "\n",
    "    combined = kim #| saket\n",
    "    \n",
    "    baseline_train_data = pairs_to_vec(combined)\n",
    "    diff = baseline_train_data.positive - baseline_train_data.negative\n",
    "    print(type(diff))\n",
    "    for index, row in diff.iterrows():\n",
    "        non_zero_columns = row[row != 0]\n",
    "        number_index = index.rsplit('_', 1)[-1]\n",
    "        if_agree = None\n",
    "        outcome = ''\n",
    "        if combined_list[int(number_index)] == 'chart 1':\n",
    "            outcome = 'agree'\n",
    "        elif combined_list[int(number_index)] == 'chart 2':\n",
    "            outcome = 'disagree'\n",
    "        else:\n",
    "            raise ValueError(\"error\")\n",
    "        with open(f'./DracoGPT_data/kim2018_for_reader/{outcome}/{int(number_index)+1}.txt', 'a') as file:\n",
    "            file.write('\\n\\n' + non_zero_columns.to_string())\n",
    "        \n",
    "    \n",
    "    diff.to_csv(\"./DracoGPT_data/kim2018_for_reader/pos-neg.csv\")\n",
    "    \n",
    "    \n",
    "    assert set(baseline_train_data.negative.columns) == set(\n",
    "        default_draco.soft_constraint_names\n",
    "    ), \"Feature names do not match.\"\n",
    "    clf = train_model(baseline_train_data)\n",
    "\n",
    "    features = baseline_train_data.negative.columns\n",
    "    print(features)\n",
    "    baseline_weights = {}\n",
    "\n",
    "    with open(f'./DracoGPT_data/DracoGPT_weights/DracoGPT_{model}_{temp}_weights', 'a') as fout:\n",
    "        for feature, weight in zip(features, clf.coef_[0]):\n",
    "            baseline_weights[f\"{feature}_weight\"] = int(weight * 1000)\n",
    "            fout.write(f\"#const {feature}_weight = {int(weight * 1000)}.\\n\")\n",
    "            \n",
    "            \n",
    "            \n",
    "    '''\n",
    "    Treat conflicting pairs\n",
    "    '''\n",
    "    combined = {}\n",
    "    with open('./docs/applications/data/kim2018_draco2.json') as file:\n",
    "        \n",
    "        i = 1\n",
    "        json_data = json.load(file)\n",
    "        print(len(json_data),len(combined_list))\n",
    "        for (pair, outcome) in zip(json_data, combined_list):\n",
    "            if outcome == \"conflicting\":\n",
    "                pair[\"source\"] = \"kim\"\n",
    "                pair[\"pair_id\"] = f'{pair[\"source\"]}_{i}'\n",
    "                combined[pair[\"pair_id\"]] = pair\n",
    "            i += 1\n",
    "    \n",
    "    baseline_train_data = pairs_to_vec(combined)\n",
    "    diff = baseline_train_data.positive - baseline_train_data.negative\n",
    "#     print(\"conflicting diff dim:\", diff)\n",
    "    for index, row in diff.iterrows():\n",
    "        non_zero_columns = row[row != 0]\n",
    "        number_index = index.rsplit('_', 1)[-1]\n",
    "        if_agree = None\n",
    "        outcome = ''\n",
    "        with open(f'./DracoGPT_data/kim2018_for_reader/conflict/{number_index}.txt', 'a') as file:\n",
    "            file.write('\\n\\n' + non_zero_columns.to_string())\n",
    "\n",
    "\n",
    "\n",
    "print(\"Training DracoGPT on Kim data\")\n",
    "train_data_prep('gpt-4-1106-preview', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "095a462b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "26380656",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:draco.data_utils:Running 116 partitions of 1152 items in parallel on {processes} processes.\n",
      "INFO:draco.data_utils:Hash of dataframe: -4999795338384740180\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1152, 296)\n",
      "C: 0.1, Dev score: 0.9421965317919075\n",
      "C: 0.5, Dev score: 0.9364161849710982\n",
      "C: 1, Dev score: 0.9364161849710982\n",
      "C: 5, Dev score: 0.9364161849710982\n",
      "C: 10, Dev score: 0.9364161849710982\n",
      "Best C:  0.1\n",
      "Final Train Score:  0.9470486111111112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/huichenwang/anaconda3/lib/python3.11/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/Users/huichenwang/anaconda3/lib/python3.11/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/Users/huichenwang/anaconda3/lib/python3.11/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/Users/huichenwang/anaconda3/lib/python3.11/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/Users/huichenwang/anaconda3/lib/python3.11/site-packages/sklearn/svm/_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/huichenwang/anaconda3/lib/python3.11/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/Users/huichenwang/anaconda3/lib/python3.11/site-packages/sklearn/svm/_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/huichenwang/anaconda3/lib/python3.11/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "kim = {}\n",
    "# saket = {}\n",
    "# with open(f'./DracoGPT_Data/saket2018_GPT/saket2018_draco2.json') as file:\n",
    "\n",
    "#     i = 0\n",
    "#     json_data = json.load(file)\n",
    "\n",
    "#     for pair in json_data:\n",
    "#         pair[\"source\"] = \"saket\"\n",
    "#         pair[\"pair_id\"] = f'{pair[\"source\"]}_{i}'\n",
    "#         saket[pair[\"pair_id\"]] = pair\n",
    "#         i += 1\n",
    "\n",
    "\n",
    "with open('./docs/applications/data/kim2018_draco2.json') as file:\n",
    "\n",
    "    i = 0\n",
    "    json_data = json.load(file)\n",
    "\n",
    "    for pair in json_data:\n",
    "        pair[\"source\"] = \"kim\"\n",
    "        pair[\"pair_id\"] = f'{pair[\"source\"]}_{i}'\n",
    "        kim[pair[\"pair_id\"]] = pair\n",
    "        i += 1\n",
    "\n",
    "combined = kim #| saket\n",
    "    \n",
    "baseline_train_data = pairs_to_vec(combined)\n",
    "print(baseline_train_data.shape)\n",
    "\n",
    "clf = train_model(baseline_train_data)\n",
    "\n",
    "features = baseline_train_data.negative.columns\n",
    "baseline_weights = {}\n",
    "\n",
    "with open('./DracoGPT_data/DracoGPT_weights/original_weights', 'w') as fout:\n",
    "    for feature, weight in zip(features, clf.coef_[0]):\n",
    "        baseline_weights[f\"{feature}_weight\"] = int(weight * 1000)\n",
    "        fout.write(f\"#const {feature}_weight = {int(weight * 1000)}.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "857b68ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4baff9ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f22ada",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e6226b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "76cc0f0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chart 2\n",
      "chart 2\n",
      "chart 2\n",
      "chart 2\n",
      "chart 2\n",
      "chart 2\n",
      "chart 2\n",
      "conflicting\n",
      "chart 1\n",
      "chart 2\n",
      "conflicting\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "conflicting\n",
      "conflicting\n",
      "conflicting\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 2\n",
      "conflicting\n",
      "chart 2\n",
      "chart 2\n",
      "conflicting\n",
      "conflicting\n",
      "chart 1\n",
      "chart 2\n",
      "conflicting\n",
      "conflicting\n",
      "chart 1\n",
      "conflicting\n",
      "chart 1\n",
      "conflicting\n",
      "chart 1\n",
      "conflicting\n",
      "conflicting\n",
      "chart 1\n",
      "conflicting\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 2\n",
      "conflicting\n",
      "conflicting\n",
      "conflicting\n",
      "chart 1\n",
      "chart 1\n",
      "conflicting\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "conflicting\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "conflicting\n",
      "chart 2\n",
      "chart 2\n",
      "chart 2\n",
      "chart 2\n",
      "chart 2\n",
      "chart 2\n",
      "chart 2\n",
      "conflicting\n",
      "conflicting\n",
      "conflicting\n",
      "chart 2\n",
      "conflicting\n",
      "chart 2\n",
      "chart 2\n",
      "chart 2\n",
      "chart 2\n",
      "chart 2\n",
      "chart 2\n",
      "chart 2\n",
      "chart 2\n",
      "chart 2\n",
      "chart 1\n",
      "conflicting\n",
      "conflicting\n",
      "conflicting\n",
      "conflicting\n",
      "conflicting\n",
      "chart 2\n",
      "conflicting\n",
      "chart 1\n",
      "conflicting\n",
      "chart 1\n",
      "chart 1\n",
      "chart 2\n",
      "chart 2\n",
      "conflicting\n",
      "chart 2\n",
      "chart 2\n",
      "chart 2\n",
      "chart 2\n",
      "chart 2\n",
      "chart 2\n",
      "chart 2\n",
      "conflicting\n",
      "conflicting\n",
      "chart 2\n",
      "chart 2\n",
      "conflicting\n",
      "conflicting\n",
      "chart 2\n",
      "conflicting\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 2\n",
      "conflicting\n",
      "conflicting\n",
      "conflicting\n",
      "chart 1\n",
      "chart 1\n",
      "conflicting\n",
      "chart 1\n",
      "conflicting\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "conflicting\n",
      "conflicting\n",
      "chart 2\n",
      "chart 2\n",
      "chart 2\n",
      "chart 2\n",
      "conflicting\n",
      "conflicting\n",
      "chart 1\n",
      "conflicting\n",
      "chart 2\n",
      "chart 1\n",
      "chart 1\n",
      "chart 2\n",
      "conflicting\n",
      "chart 2\n",
      "chart 2\n",
      "conflicting\n",
      "chart 1\n",
      "conflicting\n",
      "conflicting\n",
      "chart 1\n",
      "chart 1\n",
      "conflicting\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "conflicting\n",
      "conflicting\n",
      "conflicting\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 2\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "conflicting\n",
      "conflicting\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 2\n",
      "conflicting\n",
      "conflicting\n",
      "conflicting\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "conflicting\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "conflicting\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "conflicting\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 2\n",
      "conflicting\n",
      "conflicting\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 2\n",
      "conflicting\n",
      "conflicting\n",
      "conflicting\n",
      "conflicting\n",
      "chart 1\n",
      "conflicting\n",
      "chart 1\n",
      "conflicting\n",
      "chart 2\n",
      "chart 2\n",
      "chart 2\n",
      "conflicting\n",
      "chart 2\n",
      "chart 2\n",
      "chart 2\n",
      "conflicting\n",
      "conflicting\n",
      "conflicting\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 2\n",
      "conflicting\n",
      "conflicting\n",
      "conflicting\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "conflicting\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 2\n",
      "chart 1\n",
      "chart 2\n",
      "conflicting\n",
      "conflicting\n",
      "conflicting\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 2\n",
      "conflicting\n",
      "conflicting\n",
      "conflicting\n",
      "chart 1\n",
      "chart 1\n",
      "conflicting\n",
      "chart 1\n",
      "conflicting\n",
      "chart 1\n",
      "conflicting\n",
      "chart 2\n",
      "chart 2\n",
      "chart 2\n",
      "chart 2\n",
      "conflicting\n",
      "chart 2\n",
      "chart 2\n",
      "chart 1\n",
      "chart 2\n",
      "conflicting\n",
      "chart 2\n",
      "chart 1\n",
      "conflicting\n",
      "chart 2\n",
      "chart 1\n",
      "chart 1\n",
      "conflicting\n",
      "chart 1\n",
      "conflicting\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 2\n",
      "conflicting\n",
      "conflicting\n",
      "chart 1\n",
      "chart 1\n",
      "conflicting\n",
      "conflicting\n",
      "chart 1\n",
      "chart 1\n",
      "chart 2\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "conflicting\n",
      "conflicting\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 2\n",
      "chart 1\n",
      "chart 2\n",
      "chart 1\n",
      "chart 1\n",
      "chart 2\n",
      "chart 2\n",
      "conflicting\n",
      "conflicting\n",
      "conflicting\n",
      "conflicting\n",
      "chart 2\n",
      "chart 2\n",
      "chart 2\n",
      "chart 2\n",
      "chart 2\n",
      "conflicting\n",
      "chart 2\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 2\n",
      "chart 2\n",
      "conflicting\n",
      "chart 2\n",
      "chart 1\n",
      "conflicting\n",
      "chart 1\n",
      "conflicting\n",
      "conflicting\n",
      "chart 1\n",
      "conflicting\n",
      "chart 2\n",
      "chart 1\n",
      "conflicting\n",
      "conflicting\n",
      "chart 1\n",
      "chart 1\n",
      "conflicting\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "conflicting\n",
      "chart 2\n",
      "conflicting\n",
      "conflicting\n",
      "conflicting\n",
      "chart 2\n",
      "chart 1\n",
      "conflicting\n",
      "chart 1\n",
      "chart 2\n",
      "chart 2\n",
      "chart 2\n",
      "conflicting\n",
      "chart 2\n",
      "chart 1\n",
      "chart 1\n",
      "conflicting\n",
      "conflicting\n",
      "chart 1\n",
      "chart 1\n",
      "conflicting\n",
      "chart 1\n",
      "chart 1\n",
      "chart 2\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 2\n",
      "conflicting\n",
      "conflicting\n",
      "chart 1\n",
      "chart 1\n",
      "conflicting\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 2\n",
      "conflicting\n",
      "chart 2\n",
      "chart 2\n",
      "chart 2\n",
      "chart 2\n",
      "conflicting\n",
      "conflicting\n",
      "conflicting\n",
      "conflicting\n",
      "chart 2\n",
      "chart 2\n",
      "chart 2\n",
      "chart 2\n",
      "chart 2\n",
      "chart 2\n",
      "chart 2\n",
      "chart 2\n",
      "chart 2\n",
      "conflicting\n",
      "chart 2\n",
      "conflicting\n",
      "conflicting\n",
      "chart 2\n",
      "chart 1\n",
      "chart 2\n",
      "chart 1\n",
      "chart 1\n",
      "conflicting\n",
      "conflicting\n",
      "conflicting\n",
      "chart 1\n",
      "conflicting\n",
      "conflicting\n",
      "conflicting\n",
      "conflicting\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 2\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 2\n",
      "chart 2\n",
      "chart 2\n",
      "conflicting\n",
      "chart 2\n",
      "chart 2\n",
      "chart 2\n",
      "chart 2\n",
      "chart 2\n",
      "chart 2\n",
      "conflicting\n",
      "conflicting\n",
      "chart 2\n",
      "chart 1\n",
      "chart 2\n",
      "chart 1\n",
      "conflicting\n",
      "conflicting\n",
      "conflicting\n",
      "chart 1\n",
      "conflicting\n",
      "chart 2\n",
      "conflicting\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 2\n",
      "conflicting\n",
      "conflicting\n",
      "chart 1\n",
      "chart 1\n",
      "conflicting\n",
      "conflicting\n",
      "chart 1\n",
      "chart 1\n",
      "chart 2\n",
      "chart 1\n",
      "chart 1\n",
      "conflicting\n",
      "conflicting\n",
      "chart 1\n",
      "conflicting\n",
      "chart 2\n",
      "conflicting\n",
      "chart 2\n",
      "chart 1\n",
      "conflicting\n",
      "conflicting\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "conflicting\n",
      "conflicting\n",
      "chart 1\n",
      "conflicting\n",
      "chart 2\n",
      "conflicting\n",
      "chart 2\n",
      "chart 2\n",
      "chart 1\n",
      "conflicting\n",
      "chart 1\n",
      "chart 1\n",
      "conflicting\n",
      "chart 1\n",
      "conflicting\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "conflicting\n",
      "conflicting\n",
      "conflicting\n",
      "chart 1\n",
      "chart 1\n",
      "conflicting\n",
      "conflicting\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "conflicting\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 2\n",
      "chart 1\n",
      "chart 2\n",
      "conflicting\n",
      "chart 2\n",
      "chart 2\n",
      "chart 1\n",
      "chart 1\n",
      "conflicting\n",
      "chart 1\n",
      "conflicting\n",
      "chart 2\n",
      "chart 1\n",
      "chart 1\n",
      "chart 2\n",
      "chart 1\n",
      "chart 2\n",
      "conflicting\n",
      "chart 2\n",
      "chart 1\n",
      "chart 1\n",
      "conflicting\n",
      "conflicting\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "conflicting\n",
      "conflicting\n",
      "chart 1\n",
      "conflicting\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "conflicting\n",
      "chart 2\n",
      "chart 1\n",
      "chart 1\n",
      "conflicting\n",
      "conflicting\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "conflicting\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "conflicting\n",
      "chart 1\n",
      "chart 1\n",
      "chart 2\n",
      "conflicting\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 2\n",
      "chart 2\n",
      "conflicting\n",
      "chart 2\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 2\n",
      "chart 2\n",
      "chart 2\n",
      "chart 2\n",
      "chart 2\n",
      "chart 2\n",
      "conflicting\n",
      "conflicting\n",
      "chart 2\n",
      "chart 2\n",
      "conflicting\n",
      "chart 2\n",
      "conflicting\n",
      "conflicting\n",
      "chart 2\n",
      "chart 2\n",
      "conflicting\n",
      "conflicting\n",
      "chart 1\n",
      "conflicting\n",
      "chart 2\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 2\n",
      "conflicting\n",
      "conflicting\n",
      "conflicting\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 2\n",
      "conflicting\n",
      "chart 1\n",
      "chart 2\n",
      "conflicting\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 2\n",
      "conflicting\n",
      "conflicting\n",
      "chart 2\n",
      "conflicting\n",
      "chart 1\n",
      "conflicting\n",
      "chart 1\n",
      "conflicting\n",
      "chart 1\n",
      "chart 2\n",
      "chart 2\n",
      "chart 2\n",
      "chart 2\n",
      "chart 2\n",
      "chart 2\n",
      "chart 1\n",
      "chart 2\n",
      "chart 2\n",
      "chart 2\n",
      "conflicting\n",
      "chart 2\n",
      "chart 2\n",
      "conflicting\n",
      "conflicting\n",
      "chart 2\n",
      "conflicting\n",
      "conflicting\n",
      "chart 1\n",
      "chart 2\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "conflicting\n",
      "conflicting\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "conflicting\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "conflicting\n",
      "conflicting\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "conflicting\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "conflicting\n",
      "chart 2\n",
      "conflicting\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "conflicting\n",
      "chart 1\n",
      "conflicting\n",
      "chart 1\n",
      "conflicting\n",
      "conflicting\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "conflicting\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "conflicting\n",
      "chart 2\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "conflicting\n",
      "conflicting\n",
      "chart 1\n",
      "chart 1\n",
      "conflicting\n",
      "conflicting\n",
      "conflicting\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "conflicting\n",
      "conflicting\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "conflicting\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 2\n",
      "chart 2\n",
      "chart 2\n",
      "chart 2\n",
      "chart 2\n",
      "chart 2\n",
      "conflicting\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "conflicting\n",
      "chart 1\n",
      "conflicting\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "conflicting\n",
      "conflicting\n",
      "chart 2\n",
      "chart 2\n",
      "chart 2\n",
      "chart 1\n",
      "chart 2\n",
      "chart 2\n",
      "chart 2\n",
      "conflicting\n",
      "conflicting\n",
      "chart 2\n",
      "conflicting\n",
      "conflicting\n",
      "chart 2\n",
      "chart 1\n",
      "chart 2\n",
      "chart 1\n",
      "chart 2\n",
      "chart 2\n",
      "chart 1\n",
      "conflicting\n",
      "conflicting\n",
      "conflicting\n",
      "conflicting\n",
      "conflicting\n",
      "conflicting\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "conflicting\n",
      "conflicting\n",
      "conflicting\n",
      "chart 1\n",
      "chart 1\n",
      "conflicting\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "conflicting\n",
      "chart 1\n",
      "chart 1\n",
      "chart 2\n",
      "conflicting\n",
      "conflicting\n",
      "conflicting\n",
      "conflicting\n",
      "chart 1\n",
      "conflicting\n",
      "chart 1\n",
      "chart 1\n",
      "conflicting\n",
      "chart 1\n",
      "chart 2\n",
      "chart 1\n",
      "conflicting\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "conflicting\n",
      "conflicting\n",
      "conflicting\n",
      "conflicting\n",
      "chart 1\n",
      "chart 1\n",
      "conflicting\n",
      "conflicting\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "conflicting\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 2\n",
      "chart 2\n",
      "chart 2\n",
      "conflicting\n",
      "chart 2\n",
      "chart 1\n",
      "conflicting\n",
      "conflicting\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "conflicting\n",
      "conflicting\n",
      "chart 2\n",
      "conflicting\n",
      "conflicting\n",
      "chart 1\n",
      "conflicting\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "conflicting\n",
      "conflicting\n",
      "chart 1\n",
      "chart 1\n",
      "conflicting\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "conflicting\n",
      "conflicting\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 2\n",
      "conflicting\n",
      "conflicting\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 2\n",
      "chart 2\n",
      "conflicting\n",
      "conflicting\n",
      "chart 1\n",
      "chart 1\n",
      "conflicting\n",
      "chart 1\n",
      "conflicting\n",
      "chart 1\n",
      "chart 2\n",
      "chart 2\n",
      "chart 2\n",
      "chart 2\n",
      "chart 1\n",
      "chart 2\n",
      "chart 1\n",
      "chart 2\n",
      "conflicting\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 2\n",
      "conflicting\n",
      "conflicting\n",
      "chart 1\n",
      "chart 1\n",
      "conflicting\n",
      "conflicting\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 2\n",
      "chart 1\n",
      "conflicting\n",
      "chart 2\n",
      "conflicting\n",
      "conflicting\n",
      "chart 2\n",
      "chart 2\n",
      "chart 2\n",
      "chart 2\n",
      "chart 2\n",
      "chart 2\n",
      "conflicting\n",
      "chart 2\n",
      "chart 2\n",
      "chart 2\n",
      "conflicting\n",
      "conflicting\n",
      "conflicting\n",
      "conflicting\n",
      "chart 2\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "conflicting\n",
      "conflicting\n",
      "chart 1\n",
      "chart 1\n",
      "conflicting\n",
      "conflicting\n",
      "conflicting\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "conflicting\n",
      "conflicting\n",
      "chart 1\n",
      "chart 1\n",
      "chart 1\n",
      "conflicting\n",
      "chart 1\n",
      "chart 1\n",
      "conflicting\n",
      "845\n",
      "845\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Now we select the subset of data used to train dracogpt\n",
    "'''\n",
    "\n",
    "def filter_data(json_file_path, ranks):\n",
    "    # Read the JSON file\n",
    "    with open(json_file_path, 'r') as file:\n",
    "        json_data = json.load(file)\n",
    "\n",
    "    if len(json_data) != len(ranks):\n",
    "        raise ValueError(\"Length of ranks does not match the number of JSON objects in the file\")\n",
    "\n",
    "    updated_json_data = []\n",
    "    for json_obj, chart in zip(json_data, ranks):\n",
    "        print(chart)\n",
    "        if chart == \"chart 2\" or chart == 'chart 1':\n",
    "            updated_json_data.append(json_obj)\n",
    "        else:\n",
    "            continue\n",
    "    print(len(updated_json_data))\n",
    "    return updated_json_data\n",
    "\n",
    "\n",
    "def write_draco_subset_training_data(model, temp):\n",
    "    json_file_path = './docs/applications/data/kim2018_draco2.json'\n",
    "    updated_json = filter_data(json_file_path, res_kim)\n",
    "    print(len(updated_json))\n",
    "    directory = os.path.dirname(json_file_path)\n",
    "    new_file_path = os.path.join(directory, f'subset_kim.json')\n",
    "    with open(new_file_path, 'w') as file:\n",
    "        json.dump(updated_json, file, indent = 4)\n",
    "    \n",
    "#     json_file_path = f'./DracoGPT_data/saket2018_GPT/saket2018_draco2.json'\n",
    "#     updated_json = filter_data(json_file_path, res_saket)\n",
    "#     print(len(updated_json))\n",
    "#     directory = os.path.dirname(json_file_path)\n",
    "#     new_file_path = os.path.join(directory, f'subset_saket.json')\n",
    "#     with open(new_file_path, 'w') as file:\n",
    "#         json.dump(updated_json, file, indent = 4)\n",
    "\n",
    "write_draco_subset_training_data('gpt-4-1106-preview', 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b98fd033",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:draco.data_utils:Running 85 partitions of 845 items in parallel on {processes} processes.\n",
      "INFO:draco.data_utils:Hash of dataframe: 1496549123444742688\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "845\n",
      "C: 0.1, Dev score: 0.9291338582677166\n",
      "C: 0.5, Dev score: 0.9251968503937008\n",
      "C: 1, Dev score: 0.9212598425196851\n",
      "C: 5, Dev score: 0.9251968503937008\n",
      "C: 10, Dev score: 0.9291338582677166\n",
      "Best C:  0.1\n",
      "Final Train Score:  0.9491124260355029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/huichenwang/anaconda3/lib/python3.11/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/Users/huichenwang/anaconda3/lib/python3.11/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/Users/huichenwang/anaconda3/lib/python3.11/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/Users/huichenwang/anaconda3/lib/python3.11/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/Users/huichenwang/anaconda3/lib/python3.11/site-packages/sklearn/svm/_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/huichenwang/anaconda3/lib/python3.11/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/Users/huichenwang/anaconda3/lib/python3.11/site-packages/sklearn/svm/_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/huichenwang/anaconda3/lib/python3.11/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "kim = {}\n",
    "# saket = {}\n",
    "# with open(f'./DracoGPT_Data/saket2018_GPT/subset_saket.json') as file:\n",
    "\n",
    "#     i = 0\n",
    "#     json_data = json.load(file)\n",
    "\n",
    "#     for pair in json_data:\n",
    "#         pair[\"source\"] = \"saket\"\n",
    "#         pair[\"pair_id\"] = f'{pair[\"source\"]}_{i}'\n",
    "#         saket[pair[\"pair_id\"]] = pair\n",
    "#         i += 1\n",
    "\n",
    "\n",
    "with open(f'./DracoGPT_Data/kim2018_GPT/subset_kim.json') as file:\n",
    "\n",
    "    i = 0\n",
    "    json_data = json.load(file)\n",
    "\n",
    "    for pair in json_data:\n",
    "        pair[\"source\"] = \"kim\"\n",
    "        pair[\"pair_id\"] = f'{pair[\"source\"]}_{i}'\n",
    "        kim[pair[\"pair_id\"]] = pair\n",
    "        i += 1\n",
    "\n",
    "combined = kim #| saket\n",
    "    \n",
    "baseline_train_data = pairs_to_vec(combined)\n",
    "print(len(baseline_train_data))\n",
    "clf = train_model(baseline_train_data)\n",
    "\n",
    "features = baseline_train_data.negative.columns\n",
    "baseline_weights = {}\n",
    "\n",
    "with open(f'./DracoGPT_data/DracoGPT_weights/original_subset_weights', 'w') as fout:\n",
    "    for feature, weight in zip(features, clf.coef_[0]):\n",
    "        baseline_weights[f\"{feature}_weight\"] = int(weight * 1000)\n",
    "        fout.write(f\"#const {feature}_weight = {int(weight * 1000)}.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a01fc600",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "\n",
    "# # Paths to the original and modified files\n",
    "# # original_file_path = './DracoGPT_Data/saket2018_GPT/saket2018_draco2.json'\n",
    "# # modified_file_path = './DracoGPT_Data/saket2018_GPT/modified_saket2018_draco2.json'\n",
    "\n",
    "# original_file_path = './DracoGPT_Data/kim2018_GPT/kim2018_draco2.json'\n",
    "# modified_file_path = './DracoGPT_Data/kim2018_GPT/modified_kim2018_draco2.json'\n",
    "\n",
    "# # Read the original file\n",
    "# with open(original_file_path, 'r') as file:\n",
    "#     original_data = json.load(file)\n",
    "\n",
    "# # Read the modified file\n",
    "# with open(modified_file_path, 'r') as file:\n",
    "#     modified_data = json.load(file)\n",
    "\n",
    "# # Ensure both files have the same number of elements\n",
    "# if len(original_data) != len(modified_data):\n",
    "#     print(\"Files have different number of elements.\")\n",
    "# else:\n",
    "#     # Compare each element\n",
    "#     for original, modified in zip(original_data, modified_data):\n",
    "#         print(original == modified)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
