{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf3d0f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import clingo\n",
    "\n",
    "def parse_fact_to_symbol(fact_str):\n",
    "    # Parses a string fact and returns a clingo.Symbol\n",
    "    return clingo.parse_term(fact_str.rstrip('.'))\n",
    "\n",
    "def convert_list_to_symbols(fact_list):\n",
    "    # Converts a list of string facts to an Iterable[Symbol]\n",
    "    return [parse_fact_to_symbol(fact) for fact in fact_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd8b70a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sys\n",
    "cwd = os.getcwd()\n",
    "parent_dir = os.path.dirname(cwd)\n",
    "sys.path.append(parent_dir)\n",
    "\n",
    "import draco \n",
    "from draco import Draco\n",
    "from draco.asp_utils import get_constants\n",
    "import pandas as pd\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "30bb0e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read training sets for different Draco(GPT) models\n",
    "def read_json_files_from_directory(directory_path):\n",
    "    json_data = {}\n",
    "\n",
    "    for filename in os.listdir(directory_path):\n",
    "        if filename.endswith(\".json\"):\n",
    "            file_path = os.path.join(directory_path, filename)\n",
    "            \n",
    "            with open(file_path, 'r') as file:\n",
    "                try:\n",
    "                    data = json.load(file)\n",
    "                    json_data[filename] = data\n",
    "                except json.JSONDecodeError:\n",
    "                    print(f\"Error reading {filename}\")\n",
    "    \n",
    "    return json_data\n",
    "\n",
    "directory_path = '../rank/data'\n",
    "files = read_json_files_from_directory(directory_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "029803db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_channels(files, path):\n",
    "    positives = []\n",
    "    negatives = []\n",
    "\n",
    "    for pair in files[path]:\n",
    "        stu = 'kim2018'\n",
    "        pos_to_add = \"\"\n",
    "        neg_to_add = \"\"\n",
    "        positive_data = draco.answer_set_to_dict(convert_list_to_symbols(pair['positive']))\n",
    "        negative_data = draco.answer_set_to_dict(convert_list_to_symbols(pair['negative']))\n",
    "        if len(positive_data[\"view\"][0][\"mark\"][0][\"encoding\"]) == 2:\n",
    "            positive_data[\"view\"][0][\"mark\"][0][\"encoding\"].append(positive_data[\"view\"][0][\"facet\"][0])\n",
    "        if len(negative_data[\"view\"][0][\"mark\"][0][\"encoding\"]) == 2:\n",
    "            negative_data[\"view\"][0][\"mark\"][0][\"encoding\"].append(negative_data[\"view\"][0][\"facet\"][0])\n",
    "\n",
    "        for item in positive_data[\"view\"][0][\"mark\"][0][\"encoding\"]:\n",
    "            if item[\"field\"] == \"q1\":\n",
    "                pos_to_add += item[\"channel\"]\n",
    "#                 if item[\"channel\"] == \"xsize\":\n",
    "#                     print(\"error\")\n",
    "        for item in positive_data[\"view\"][0][\"mark\"][0][\"encoding\"]:\n",
    "            if item[\"field\"] == \"q2\":\n",
    "                pos_to_add += \" \"+item[\"channel\"]\n",
    "        for item in positive_data[\"view\"][0][\"mark\"][0][\"encoding\"]:\n",
    "            if item[\"field\"] == \"n\":\n",
    "                pos_to_add += \" \"+item[\"channel\"] \n",
    "        pos_to_add += \" \" + positive_data[\"task\"]\n",
    "\n",
    "        for item in negative_data[\"view\"][0][\"mark\"][0][\"encoding\"]:\n",
    "            if item[\"field\"] == \"q1\":\n",
    "                neg_to_add += item[\"channel\"]\n",
    "        for item in negative_data[\"view\"][0][\"mark\"][0][\"encoding\"]:\n",
    "            if item[\"field\"] == \"q2\":\n",
    "                neg_to_add += \" \"+item[\"channel\"]\n",
    "        for item in negative_data[\"view\"][0][\"mark\"][0][\"encoding\"]:\n",
    "            if item[\"field\"] == \"n\":\n",
    "                neg_to_add += \" \"+item[\"channel\"]   \n",
    "        neg_to_add += \" \" + positive_data[\"task\"]\n",
    "        \n",
    "        positives.append(pos_to_add)\n",
    "        negatives.append(neg_to_add)\n",
    "    return positives, negatives\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b45b450",
   "metadata": {},
   "outputs": [],
   "source": [
    "positives, negatives = get_channels(files, \"kim2018_draco2.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2bfce8c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def get_stringified_channels(positives, negatives):\n",
    "    pos_c = Counter(positives)\n",
    "    neg_c = Counter(negatives)\n",
    "    return pos_c, neg_c\n",
    "\n",
    "pos_c, neg_c = get_stringified_channels(positives, negatives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7112c735",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'y x color value': 99,\n",
       "         'size x y summary': 84,\n",
       "         'y color x summary': 76,\n",
       "         'y color x value': 75,\n",
       "         'size y x summary': 71,\n",
       "         'y size x value': 70,\n",
       "         'x color y value': 69,\n",
       "         'x y color value': 69,\n",
       "         'y x row value': 68,\n",
       "         'x size y value': 66,\n",
       "         'x y row value': 60,\n",
       "         'x color y summary': 58,\n",
       "         'y size x summary': 52,\n",
       "         'x size y summary': 43,\n",
       "         'x y row summary': 38,\n",
       "         'y x row summary': 35,\n",
       "         'color x y summary': 28,\n",
       "         'size y x value': 20,\n",
       "         'size x y value': 20,\n",
       "         'x y color summary': 16,\n",
       "         'y x color summary': 16,\n",
       "         'color y x summary': 11,\n",
       "         'color x y value': 5,\n",
       "         'color y x value': 3})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "79fbd7f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def process_counts(counter):\n",
    "#     processed = Counter()\n",
    "#     for key, count in counter.items():\n",
    "#         new_key = key.replace(' summary', '').replace(' value', '')\n",
    "#         processed[new_key] += count\n",
    "#     return processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad8311c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def transform_labels(labels):\n",
    "#     ret = []\n",
    "#     for l in labels:\n",
    "#         ls = l.split(\" \")\n",
    "#         ret.append(\"q1:\"+ls[0]+ \" q2:\"+ls[1] + \" n:\"+ls[2])\n",
    "#     return ret"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a8e259",
   "metadata": {},
   "source": [
    "## Scatterplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8567083c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_program(weights):\n",
    "    assign_prog = \"\"\n",
    "\n",
    "    for name in weights:\n",
    "        match = re.search(\"(.*)_weight\", name)\n",
    "        if match:\n",
    "            assign_prog += f\"preference_weight({match.group(1)},{name}).\\n\"\n",
    "        else:\n",
    "            logging.warning(\n",
    "                f'Constant \"{name}\" doesn\\'t end with \"_weight\", so it\\'s not assigned.'\n",
    "            )\n",
    "\n",
    "    return assign_prog\n",
    "\n",
    "def read_weights(weight_path):\n",
    "    \"\"\"Reads the weights file and assigns the weights to the preferences.\"\"\"\n",
    "    with open(weight_path) as weight_constants:\n",
    "        const_prog = weight_constants.read()\n",
    "        const_dict = get_constants(const_prog)\n",
    "        return const_dict\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0e8e91a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "default_draco = Draco()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b36fe378",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_draco_costs = []\n",
    "rank_costs = []\n",
    "recommend_costs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4bc70e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rank_and_concat(l):\n",
    "    # Sort the lists of strings in the input dictionary\n",
    "    sorted_positive = sorted(l)\n",
    "    return \",\".join(sorted_positive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "03c5b368",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_costs(directory_path, json_name, penalties):\n",
    "    costs = []\n",
    "\n",
    "    files = read_json_files_from_directory(directory_path)\n",
    "    \n",
    "    for pair in files[json_name]:\n",
    "        cost = 0\n",
    "        \n",
    "        for k, v in default_draco.count_preferences(pair[\"positive\"]).items():\n",
    "            \n",
    "            cost += v*penalties[k + '_weight'] / 1000   \n",
    "        costs.append(cost)\n",
    "        \n",
    "        \n",
    "        cost = 0\n",
    "        for k, v in default_draco.count_preferences(pair[\"negative\"]).items():\n",
    "            cost += v*penalties[k + '_weight'] / 1000\n",
    "            \n",
    "        costs.append(cost)\n",
    "      \n",
    "    return costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "db87f193",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_facts(directory_path, json_name, penalties):\n",
    "    \n",
    "    facts = []\n",
    "\n",
    "    files = read_json_files_from_directory(directory_path)\n",
    "    \n",
    "    for pair in files[json_name]:\n",
    "        \n",
    "        for k, v in default_draco.count_preferences(pair[\"positive\"]).items():\n",
    "            positive_data = draco.answer_set_to_dict(convert_list_to_symbols(pair['positive']))\n",
    "            pos_encodings = {}\n",
    "            if len(positive_data[\"view\"][0][\"mark\"][0][\"encoding\"]) == 2:\n",
    "                positive_data[\"view\"][0][\"mark\"][0][\"encoding\"].append(positive_data[\"view\"][0][\"facet\"][0])\n",
    "         \n",
    "            for item in positive_data[\"view\"][0][\"mark\"][0][\"encoding\"]:\n",
    "                if item[\"field\"] == \"q1\":\n",
    "                    pos_encodings['q1'] = item[\"channel\"]\n",
    "            for item in positive_data[\"view\"][0][\"mark\"][0][\"encoding\"]:\n",
    "                if item[\"field\"] == \"q2\":\n",
    "                    pos_encodings['q2'] = item[\"channel\"]\n",
    "            for item in positive_data[\"view\"][0][\"mark\"][0][\"encoding\"]:\n",
    "                if item[\"field\"] == \"n\":\n",
    "                    pos_encodings['n'] = item[\"channel\"] \n",
    "            pos_encodings['task'] = positive_data[\"task\"]\n",
    "            \n",
    "        facts.append(pos_encodings)\n",
    "        \n",
    "        for k, v in default_draco.count_preferences(pair[\"negative\"]).items():\n",
    "            negative_data = draco.answer_set_to_dict(convert_list_to_symbols(pair['negative']))\n",
    "            neg_encodings = {}\n",
    "            if len(negative_data[\"view\"][0][\"mark\"][0][\"encoding\"]) == 2:\n",
    "                negative_data[\"view\"][0][\"mark\"][0][\"encoding\"].append(negative_data[\"view\"][0][\"facet\"][0])\n",
    "         \n",
    "            for item in negative_data[\"view\"][0][\"mark\"][0][\"encoding\"]:\n",
    "                if item[\"field\"] == \"q1\":\n",
    "                    neg_encodings['q1'] = item[\"channel\"]\n",
    "            for item in negative_data[\"view\"][0][\"mark\"][0][\"encoding\"]:\n",
    "                if item[\"field\"] == \"q2\":\n",
    "                    neg_encodings['q2'] = item[\"channel\"]\n",
    "            for item in negative_data[\"view\"][0][\"mark\"][0][\"encoding\"]:\n",
    "                if item[\"field\"] == \"n\":\n",
    "                    neg_encodings['n'] = item[\"channel\"] \n",
    "            neg_encodings['task'] = negative_data[\"task\"]\n",
    "            \n",
    "          \n",
    "        facts.append(neg_encodings)\n",
    "        \n",
    "    return facts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b43f1b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "penalties = read_weights(\"./weights/DracoGPT_recommend_gpt-4-0125-preview_0_weights.txt\")\n",
    "gpt4_turbo_recommend_costs = compute_costs('../rank/data', \"kim2018_draco2.json\", penalties)\n",
    "# gpt4_turbo_recommend_facts = get_facts('../rank/data', \"kim2018_draco2.json\", penalties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "839197c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "penalties = read_weights(\"./weights/DracoGPT_recommend_gpt-4-0613_0_weights.txt\")\n",
    "gpt4_recommend_costs = compute_costs('../rank/data', \"kim2018_draco2.json\", penalties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c9763189",
   "metadata": {},
   "outputs": [],
   "source": [
    "penalties = read_weights(\"./weights/DracoGPT_recommend_gpt-3.5-turbo-0125_0_weights.txt\")\n",
    "chatgpt_recommend_costs = compute_costs('../rank/data', \"kim2018_draco2.json\", penalties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "28fe4c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "penalties = read_weights(\"./weights/DracoGPT_recommend_altair_gpt-4-0125-preview_0_weights.txt\")\n",
    "altair_gpt4_turbo_recommend_costs = compute_costs('../rank/data', \"kim2018_draco2.json\", penalties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3b871bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "penalties = read_weights(\"./weights/DracoGPT_recommend_altair_gpt-4-0613_0_weights.txt\")\n",
    "altair_gpt4_recommend_costs = compute_costs('../rank/data', \"kim2018_draco2.json\", penalties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "799e324f",
   "metadata": {},
   "outputs": [],
   "source": [
    "penalties = read_weights(\"../rank/weights/DracoGPT_gpt-4-0125-preview_0_weights.txt\")\n",
    "gpt4_turbo_rank_costs = compute_costs('../rank/data', \"kim2018_draco2.json\", penalties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "771aa7fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "penalties = read_weights(\"../rank/weights/DracoGPT_gpt-4-0613_0_weights.txt\")\n",
    "gpt4_rank_costs = compute_costs('../rank/data', \"kim2018_draco2.json\", penalties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "78497d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "penalties = read_weights(\"../rank/weights/DracoGPT_gpt-3.5-turbo-0125_0_weights.txt\")\n",
    "chatgpt_rank_costs = compute_costs('../rank/data', \"kim2018_draco2.json\", penalties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "01d40cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "penalties = read_weights(\"../rank/weights/original_weights.txt\")\n",
    "original_draco_costs = compute_costs('../rank/data', \"kim2018_draco2.json\", penalties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8fc3003b-4ac5-448d-a109-e7c48353066a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "filename = \"costs_and_facts.csv\"\n",
    "col_names = ['kim', 'rank', 'rec_vl', 'rec_altair', 'q1', 'q2', 'n', 'task']\n",
    "\n",
    "distinct_rows = set()\n",
    "\n",
    "# Writing data to a CSV file\n",
    "with open(filename, mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(col_names)  # Write the header\n",
    "    \n",
    "    # Zip the lists and write each row to the CSV\n",
    "    for a,b,c,d,e in zip(original_draco_costs, gpt4_turbo_rank_costs, gpt4_turbo_recommend_costs, altair_gpt4_turbo_recommend_costs, gpt4_turbo_recommend_facts):\n",
    "        row = (a, b, c, d, e['q1'], e['q2'], e['n'], e['task'])\n",
    "        if row in distinct_rows:\n",
    "            continue\n",
    "        distinct_rows.add((a, b, c, d, e['q1'], e['q2'], e['n'], e['task']))\n",
    "        writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f4678e2c-1a29-44ce-8b48-6e80c3c050a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dedup(lists):\n",
    "    s = set()\n",
    "    res = []\n",
    "    for items in zip(*lists):\n",
    "        s.add(items)\n",
    "    for item in s:\n",
    "        res.append([item[0],item[1],item[2]])\n",
    "    \n",
    "    return list(map(list, zip(*res)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4865852d-6a1f-4acd-9c08-833a1c1718ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_lists_1 = dedup([gpt4_turbo_rank_costs, original_draco_costs, altair_gpt4_turbo_recommend_costs])\n",
    "data_lists_2 = dedup([gpt4_turbo_recommend_costs, original_draco_costs, altair_gpt4_turbo_recommend_costs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c643ae34",
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_vs_kim = {\n",
    "    \"rank\": data_lists_1[0],\n",
    "    \"kim\": data_lists_1[1]\n",
    "}\n",
    "with open(\"rank_vs_kim.json\", \"w\") as file:\n",
    "    json.dump(rank_vs_kim, file, indent=4)\n",
    "\n",
    "rec_vl_vs_kim = {\n",
    "    \"rec_vl\": data_lists_2[0],\n",
    "    \"kim\": data_lists_2[1]\n",
    "}\n",
    "with open(\"rec_vl_vs_kim.json\", \"w\") as file:\n",
    "    json.dump(rec_vl_vs_kim, file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fc3ec979",
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_vs_rec_vl = {\n",
    "    \"rank\": data_lists[0],\n",
    "    \"rec_vl\": data_lists[1]\n",
    "}\n",
    "with open(\"rank_vs_rec_vl.json\", \"w\") as file:\n",
    "    json.dump(rank_vs_rec_vl, file, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "13960a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_vl_vs_rec_altair = {\n",
    "    \"rec_vl\": data_lists[0],\n",
    "    \"rec_altair\": data_lists[1]\n",
    "}\n",
    "with open(\"rec_vl_vs_rec_altair.json\", \"w\") as file:\n",
    "    json.dump(rec_vl_vs_rec_altair, file, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
